{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Applied Deep Learning & Computer Vision using Pytorch (Intro)\n",
        "#Application: Classify Damaged RAM Cones (damage vs non-damage) in the National Ignition Facility (NIF) optics recycle loop\n",
        "\n",
        "*Damaged RAM Cones: protocol used to mitigate damage on NIF optics in order to recycle and extend life of optics used to penetrate lase beam energy to dense center (this creates nuclear fusion)*"
      ],
      "metadata": {
        "id": "uUJCFgp3nTrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will discuss the main things we need to do to apply a Computer Vision deep learning model (eg. ResNet or Convnext) to predict Damaged RAM Cones (see slide).\n",
        "\n",
        "\n",
        " 1. prepare data,\n",
        " 2. prepare dataloaders,\n",
        " 3. train setup,\n",
        " 4. test/evaluation setup,\n",
        " 5. model setup\n",
        "\n",
        "\n",
        "\n",
        "A lot of Machine Learning involves **data preprocessing** (1) (prior to actual training and testing the model) which involves preparing inputs that can be well undestood by the model\n",
        "- NOTE: In this case we assume that the preprocessed data is already stored in a numpy array (so data peprocessing can be discussed in another notebook)\n",
        "  - preprocessing (for this specific app) involved a lot of steps, eg.:\n",
        "    - read images from metrology server\n",
        "    - extract damage metadata\n",
        "    - extract image features of (center) cone in question (eg. Hough Circle finding/counting, segmentation)\n",
        "- we therefore directly apply dataloader function to labels and data saved as a CSV and numpy array, repsectively\n",
        "  - labels refer to the class in this case (Damage: 1 or Non-Damages RAM cone: 0)\n",
        "  - images refer to the multidimensional image data (750x750x3 in this case)\n",
        "    - numpy array is a common storage method because numpy array can be quickly converted to tensors\n",
        "  - these need to be accessible to this code (eg. on the same CPU this is run, eg. Google Drive)\n"
      ],
      "metadata": {
        "id": "biDxLoTm7cw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SETUP environment\n",
        "- imports\n",
        "  - good to include sklearn and/or torchmetrics (analysis/calcluation/presentation of results), and common trasnforms in addition to torch (deep learning), cv2 (computer vision), and torchvision\n",
        "  - other book-keeping tools, eg. time, to write time of train to file ...and read from config file (where we store our train configurations for current train)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GgnNEEgjihSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w_ZjguMg-i3"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "import cv2\n",
        "import torchmetrics\n",
        "import matplotlib.pyplot as plt\n",
        "from torchmetrics.classification import BinaryROC\n",
        "from configparser import ConfigParser\n",
        "from torchvision.transforms import (CenterCrop,\n",
        "                                    Compose,\n",
        "                                    ColorJitter,\n",
        "                                    Normalize,\n",
        "                                    RandomRotation,\n",
        "                                    RandomAffine,\n",
        "                                    RandomHorizontalFlip,\n",
        "                                    RandomVerticalFlip,\n",
        "                                    RandomApply,\n",
        "                                    RandomCrop,\n",
        "                                    ToTensor,\n",
        "                                    Resize)\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "\n",
        "year = now.strftime(\"%Y\")\n",
        "month = now.strftime(\"%m\")\n",
        "day = now.strftime(\"%d\")\n",
        "dtime = now.strftime(\"%H%M%S\")\n",
        "\n",
        "# can be used to save model weights/states\n",
        "new = \"states/\" + month + day + year + dtime + \"/\"\n",
        "\n",
        "# os.mkdir(new)\n",
        "\n",
        "date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "print(\"Train/test date and time:\", date_time)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transforms\n",
        "\n",
        "  - transforms can be used to increase the size of the data by artificial augmentation\n",
        "    - more variation in train examples makes the model more robust to new data\n",
        "  - transforms can also be useful for handling class imbalance (as we have here in this application) where we have only ~5% damaged RAMs because we can add more versions of just the minority class\n",
        "    - other methods to handle this class-imbalance include increasing threshold for non-damage prediction, increasing the minority sampling rate (in the dataloader)\n",
        "  - we may also need general transforms like resize to be applied to both test and train data"
      ],
      "metadata": {
        "id": "F-n-jfMgD0tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# required format for images and labels in torch\n",
        "t = torchvision.transforms.ToTensor()\n",
        "t0 = RandomRotation((-90,-90))\n",
        "t1 = RandomRotation((90,90))\n",
        "t2 = RandomVerticalFlip(p=1.0)\n",
        "t3 = RandomHorizontalFlip(p=1.0)\n",
        "t4 = RandomAffine(45,scale=(0.8,1.5))\n",
        "t5 = RandomAffine(45,shear = 20)\n",
        "t6 = RandomApply([ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)), RandomAffine(45, scale=(0.8,1.5)), RandomAffine(45, shear=20)], p = 0.8)\n",
        "t7 = RandomApply([t0, t1, t2, t3], p = 0.2)\n",
        "t8 = CenterCrop(752)\n",
        "t9 = Resize(520)#736"
      ],
      "metadata": {
        "id": "96lcLGSvDyH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare the dataloaders from stored datasets\n",
        "- we first write a collate function used as input to torch `data.DataLoader` function\n",
        "  - we will see this in the data prep function described next\n",
        "- these dataloaders usually take input of lists of tuples of data and labels converted to float or int (in this case images and \"Damage\":1 or \"Non-Damage\":0)\n",
        " - eg. (image, int)\n",
        "- during training/testing collate takes the tuples and converts them to separate tensors (of variable batch size, input) which is in a format that can be input into the model layers\n",
        " - can also apply in training transforms ( but better to do on GPU)\n",
        " - can also add another piece of metadata to the tuple if there are mutiple labels to learn from (eg. we may want to use a combination of scalar and image data as model input)\n"
      ],
      "metadata": {
        "id": "cj7OdmsSkRpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# used as input to dataloader; each batch needs to be a tensor of images and a tensor of labels\n",
        "def collate_fn(examples):\n",
        "    pixel_values = torch.stack([t9(t8(t(example[0]))) for example in examples])\n",
        "    labels = torch.tensor([example[1] for example in examples])\n",
        "    p = torch.tensor([example[2] for example in examples])\n",
        "    c = torch.tensor([example[3] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels, \"count\": c, \"protocol\": p}"
      ],
      "metadata": {
        "id": "z72U2aX0kKsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `prep_data_load` function\n",
        "1. reads the data into numpy arrays (can also be done with pandas for easy tools for big metadata):\n",
        " - images from numpy arrays\n",
        "  - numpy array can usually store large image data\n",
        " - labels from CSV file\n",
        "  - csv good way to store metadata and labels\n",
        "\n",
        "2. divides data up into test/train/eval sets\n",
        " - usually 70/15/15 % split is good\n",
        "  - can also try different splits of the dataset for testing (eg. of same size and average, train with everything else)\n",
        "\n",
        "3. applies normalization to float images, applies integer conversion to labels\n",
        "  \n",
        "4. creates tuples of labels and normalized images from numpy arrays\n",
        "\n",
        "5. uses these along with collate function as input to `data.DataLoader` functions, which are returned for use as input to train and evaluation functions\n",
        "  - `shuffle` train set always, `drop_last` useful for testing when data-size not divisible by batch size"
      ],
      "metadata": {
        "id": "Adjhdca9inuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in meta-data from CSV and corresponding image data from .npy\n",
        "# load up data-loader (creates the train/test batches)\n",
        "# Note: we have a sepaarate csv, npy for train/test\n",
        "def prep_data_load(batch_size, ims1_path, meta1_path, test_ims_path, test_meta_path, cols, split = 0.3, k = 2):\n",
        "  df1 = pd.read_csv(meta1_path[0])\n",
        "  for i in range(1,len(meta1_path)):\n",
        "    df2 = pd.read_csv(meta1_path[i])\n",
        "    df1 = df1.append(df2, ignore_index=True)\n",
        "  df1.to_csv(\"drp2.csv\", index=False)\n",
        "\n",
        "  ims = np.load(ims1_path[0])\n",
        "  test_ims = np.load(test_ims_path)\n",
        "\n",
        "  for i in range(1,len(ims1_path)):\n",
        "      ims= np.concatenate([ims, np.load(ims1_path[i])], axis=0)\n",
        "\n",
        "  with open('dr2.csv', 'r') as f:\n",
        "    reader = csv.reader(f, delimiter=',')\n",
        "    attributes = next(reader)\n",
        "    meta1 = list(reader)  # np.array(list(reader))\n",
        "\n",
        "  with open(test_meta_path, 'r') as f:\n",
        "    reader = csv.reader(f, delimiter=',')\n",
        "    attributes = next(reader)\n",
        "    test_meta = list(reader)  # np.array(list(reader))\n",
        "\n",
        "  train, valid, test = [], [], []\n",
        "  ims = ims.astype(np.float32)\n",
        "  test_ims = test_ims.astype(np.float32)\n",
        "\n",
        "  eval_num = round(len(meta1)*split)\n",
        "  tot = ims.shape[0]\n",
        "  test_inds = [i for i in range(test_ims.shape[0])]\n",
        "  eval_inds = [i for i in range(k*eval_num, (k+1)*eval_num)]\n",
        "\n",
        "  train_inds = [ i for i in range(k*eval_num)] + [i for i in range((k+1)*eval_num, tot)]\n",
        "\n",
        "  print(\"Original train length\", len(train_inds), \"eval length\", len(eval_inds), \"test length\", len(test_inds))\n",
        "  immn = [ims[:,:,:,0].mean(), ims[:,:,:,1].mean(), ims[:,:,:,2].mean()]\n",
        "  imstd = [ims[:,:,:,0].std(), ims[:,:,:,1].std(), ims[:,:,:,2].std()]\n",
        "  imnorm = Normalize(mean = immn, std = imstd)\n",
        "  print(\"immn, imstd, imnorm\", immn, imstd, imnorm)\n",
        "\n",
        "  for i in range(ims.shape[0]):\n",
        "    label = int(meta1[i][-4])\n",
        "    im1 = ims[i]\n",
        "    c = meta1[i][-3].split('RAM')[-1]\n",
        "    p = int(meta1[i][1])\n",
        "    if i in eval_inds:\n",
        "     valid.append((im1, label, p, c))\n",
        "    else:\n",
        "      train.append((im1, label, p, c))\n",
        "\n",
        "  for i in range(test_ims.shape[0]):\n",
        "    im1 = test_ims[i]\n",
        "    c = test_meta1[i][-1].split('RAM')[-1]\n",
        "    p = int(test_meta1[i][cols[2]])\n",
        "    test.append((im1, 0, p, c))\n",
        "\n",
        "  print(\"check train and test lengths:\", len(train), len(valid))\n",
        "  test_loader = data.DataLoader(test, collate_fn=collate_fn, batch_size=1, shuffle = False)\n",
        "  eval_loader = data.DataLoader(valid, collate_fn=collate_fn, batch_size=1, shuffle = False)\n",
        "  train_loader = data.DataLoader(train, collate_fn=collate_fn, batch_size=batch_size, shuffle = True, drop_last = True)\n",
        "  return train_loader, test_loader, eval_loader, imnorm"
      ],
      "metadata": {
        "id": "zWUNdBSG5os7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Notes about data prepping and loading\n",
        "\n",
        "- data may be too large to apply transforms pre-training (may not fit on disk, or in memory)\n",
        "- normalizing the training data is a standard in machine learning\n",
        "  - puts data on similar scale without losing information\n",
        "  - reduces storage space of data\n",
        "  - reduces training time\n",
        "  - provides stability during training (eg. weights update applied evenly thorugh data) reduces possibility of exponential decay\n",
        "- data may be in chunks, needs to be combined if cannot store all data in one array\n",
        "- probably have separate test set\n",
        "  - eg. to test on new data"
      ],
      "metadata": {
        "id": "K9Op3BWyIn5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models setup/define\n",
        "- wrap any newly defined model in a class with `torch.nn.Module` inheritance\n",
        " -  otherwise torch, sklearn, HuggingFace, etc. have pre-defined models (load with one line of code)\n",
        "- models usually have an `init` of model, model layers, and forward function which applies those to the input data when the model is applied in practice\n",
        "\n",
        "below are some simple models I created for this application"
      ],
      "metadata": {
        "id": "JkpRkRfTEq0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model `FinalModelWrapper` below is an example of test time transforms\n",
        " - averages predctions of different transforms of 1 image\n"
      ],
      "metadata": {
        "id": "qb3szu7rF5Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# averages predictions on each rotation/flip\n",
        "class FinalModelWrapper(torch.nn.Module):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "  def forward(self, x):\n",
        "    y = self.model(x)\n",
        "    xmod = torch.rot90(x, 1, (2, 3))\n",
        "    y = torch.add(y, self.model(xmod))\n",
        "    xmod = torch.flip(xmod, (3,))\n",
        "    y = torch.add(y, self.model(xmod))\n",
        "    xmod = torch.flip(xmod, (2,))\n",
        "    y = torch.add(y, self.model(xmod))\n",
        "    xmod = torch.flip(x, (3,))\n",
        "    y = torch.add(y, self.model(xmod))\n",
        "    xmod = torch.flip(xmod, (2,))\n",
        "    y = torch.add(y, self.model(xmod))\n",
        "    xmod = torch.flip(x, (2,))\n",
        "    y = torch.add(y, self.model(xmod))\n",
        "    xmod = torch.rot90(xmod, 1, (2, 3))\n",
        "    y = torch.add(y, self.model(xmod))\n",
        "    y = y/8.0\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "30GRv13tF2Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `TFModel`: wrapper for a different library model (HuggingFace) which puts output of model in element 1, unlike torch models"
      ],
      "metadata": {
        "id": "XjStOKi0F9Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TFModel(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.model(x)[0]\n",
        "        return y"
      ],
      "metadata": {
        "id": "WbnJRfbEEpdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `TwoModelWrapper`: model to average outputs of two differnet models to increase accracy (eg. ensemble method)"
      ],
      "metadata": {
        "id": "fJRIsNPgahcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoModelWrapper(torch.nn.Module):\n",
        "    def __init__(self, model0, model1):\n",
        "        super().__init__()\n",
        "        self.model0 = model0\n",
        "        self.model1 = model1\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.model1(x)\n",
        "        y = torch.add(y, self.model0(x).logits)\n",
        "        y = y / 2.0\n",
        "\n",
        "        return y"
      ],
      "metadata": {
        "id": "YHQ996A_acG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `MultiInputSimpleV`: model to include metadat in prediction\n",
        "- eg. we can include the number of RAMEOs in this DL application\n",
        " - RAMEOs are other RAM cones which overlap the RAM in the center (which we are predicting)\n",
        " - other overlapping RAMEOs may increase probability of damage so this information could help the model decide"
      ],
      "metadata": {
        "id": "m913naIBaqKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiInputSimpleV(torch.nn.Module):\n",
        "  def __init__(self, modelb):\n",
        "    super().__init__()\n",
        "    self.modela = modelb\n",
        "    self.fc = nn.Sequential(\n",
        "      #nn.Dropout(0.2),\n",
        "      nn.Linear(128, 64), #\n",
        "      nn.PReLU(),\n",
        "      nn.BatchNorm1d(64),\n",
        "      nn.Dropout(0.3),\n",
        "      nn.Linear(64, 1),\n",
        "    )\n",
        "  def forward(self, x1, c, p):\n",
        "\n",
        "    o1 = self.modela(x1)\n",
        "    c = c.unsqueeze(1) #add dim 1\n",
        "    p = p.unsqueeze(1)\n",
        "    combined = torch.cat((c, p, o1), dim = 1)\n",
        "    out = self.fc(combined)\n",
        "    return out"
      ],
      "metadata": {
        "id": "Glc09CaaaegL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Flattened Model layer before Fully Connected layers\n",
        "\n",
        "- last layer of model is flattened (eg. there will be a `num_classes` input for most predefined models)\n",
        "- last flattened layer concatenated with `torch.cat` with scalar metadata\n",
        "- `unsqueeze` is required to convert scalar input to 1-d tensor before concatenation so the dimensions math (`squeeze` removes it)"
      ],
      "metadata": {
        "id": "8jA5-ZZOQFbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fully Model Layers\n",
        "\n",
        "- Linear: fully connected nodes\n",
        "  - `torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)`\n",
        "- `PReLU` (Parameterized Rectified Linear Unit): Relu (y = max(0,x)) is an activation function we need to have which introduces non-linearity to network\n",
        " - we need to have a model which can represent non-linear functions\n",
        " - `PReLU` is a variation (y = max(0,x) + a* min(0,x))\n",
        "  - Certain activation functions, like the sigmoid function, squishes a large input space into a small input space between 0 and 1.\n",
        "  - PRelu and Leaky ReLu allow a small negative output\n",
        "- `BatchNorm1D`: Normalization between batches can help with stability\n",
        "\n",
        "- `Dropout`: random dropout of nodes, provides regularization, prevents overfitting and cross correlation\n",
        "\n",
        "- finally reduce final model `Linear` layer dimension to the number of classes ( one output representing th eprobability of each class)"
      ],
      "metadata": {
        "id": "LQe-6IDt2V96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test and evaluation function\n",
        "- uses validation and test loaders\n",
        "- validation is done during training in order to see (during training) how well the model is doing on new data\n",
        " - eg. we can see when the model **converges**\n",
        " - besure not to overfit model though by training to long( eg. adapt to test set)\n",
        "  - **bias vs variance** trade off\n",
        "    - Bias (underfitting) represents the error due to overly simplistic assumptions\n",
        "    - variance model follows closely to the train data\n",
        "- test is done only after the model is fully trained and the best model is saved\n",
        " - usually we use best or last model by looking at the validation set accuracy (or class averaged accuracy)\n",
        "- valid is done during training eg. every 1, 5, 10 epochs\n",
        "\n",
        "- note that no weights updated here, loss is calucated, no packpropogation; just using save model weights\n",
        "- still best to do this on GPU and/or in batches if test set is large\n",
        "\n",
        "##analysis of results:\n",
        "- classification problem so we create a **confusion matrix** (sklearn and/or pandas are good tools for things like this and other accuracy metrics)\n",
        "- also saved best model to **.pt** file to store for after training, future use\n",
        " - prod code usually reads in a **JIT traced model** (so we may save this as well)\n",
        "- binary problem so we apply **sigmoid**, round\n",
        "  - threshold may vary (eg. in cases wher we have class imbalance\n",
        "  - multiclass would have been softmax\n",
        "  these functions squish the sum of the final output values to between 0 and 1 so we can round or choose the max to get the prediction\n"
      ],
      "metadata": {
        "id": "fZ6ZO_eeb6Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate classification accuracy of binary model, check if score improved,\n",
        "# if yes, update best score, save weights, and show new confusion matrix\n",
        "def evaluate(model, test_loader, eval_loader, testforms, score = 0.0, test = False, thresh = 0.5):\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  y_true, y_pred, dats, confs = [], [], [], []\n",
        "\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  if test == True:\n",
        "      eval_loader = test_loader\n",
        "      with open(test_meta_path, 'r') as f:\n",
        "        # this is for reading name labels in test set so we can write\n",
        "          reader = csv.reader(f, delimiter=',')\n",
        "          attributes = next(reader)\n",
        "          test_meta = list(reader)  # np.array(list(reader))\n",
        "  with torch.no_grad():\n",
        "    for i, batch in enumerate(eval_loader):\n",
        "      x = batch['pixel_values'].float()\n",
        "      y = batch['labels']\n",
        "      p = batch['protocol'].float()\n",
        "      c = batch['count'].float()\n",
        "      x, p, c = x.to(device), p.to(device), c.to(device)\n",
        "      x = testforms(x)\n",
        "      #out = model(x)\n",
        "      out = model(x, p, c)\n",
        "      # adjust out activation function if mc\n",
        "      if test == True:\n",
        "        conf = torch.sigmoid(out).detach().cpu().numpy()[:,0].tolist()\n",
        "        pred = torch.round(torch.sigmoid(out)).detach().cpu().numpy()[:,0].tolist()\n",
        "        name = test_meta[i][0]\n",
        "        y_true = y.numpy().tolist()\n",
        "        if (y_true[0] == 1) and (y_true[0] != pred[0]):\n",
        "\n",
        "            print(i)#, name)#, pred[0], y_true[0])\n",
        "        if pred[0] == 0:\n",
        "            conf = 1 - conf[0]\n",
        "        else:\n",
        "            conf = conf[0]\n",
        "        dats.append([name, pred[0], conf ])\n",
        "      else:\n",
        "\n",
        "        conf0 = torch.sigmoid(out).detach().cpu().numpy()[:,0].tolist()\n",
        "        confs += conf0\n",
        "        pred = [1 if x > thresh else 0 for x in conf0 ]\n",
        "        #pred = torch.round(torch.sigmoid(out)).detach().cpu().numpy()[:, 0].tolist()\n",
        "\n",
        "        y_pred += pred\n",
        "\n",
        "        true = y.numpy().tolist()\n",
        "        y_true += true\n",
        "\n",
        "    if test == False:\n",
        "        print(\"Accuracy score: \", accuracy_score(y_true, y_pred))\n",
        "\n",
        "        recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
        "        #precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
        "\n",
        "        print(\"Class averaged accuracy (np.sum(recall)/2)\", np.sum(recall)/2)\n",
        "        if score < np.sum(recall)/2:#accuracy_score(y_true, y_pred):\n",
        "          y_true = pd.Series(y_true, name = \"Actual\")\n",
        "          y_pred = pd.Series(y_pred, name = \"Predicted\")\n",
        "          df_confusion = pd.crosstab(y_true, y_pred)\n",
        "          print(df_confusion)\n",
        "\n",
        "          cm = confusion_matrix(y_true, y_pred)\n",
        "          #print(cm)\n",
        "          recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
        "          #precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
        "          #print(precision)\n",
        "          print(\"IMPROVED class averaged accuracy (np.sum(recall)/2)\", np.sum(recall)/2)\n",
        "          score = np.sum(recall)/2\n",
        "  if test == True:\n",
        "\n",
        "      with open(\"results_test_meta.csv\", 'w', newline='') as csvfile:\n",
        "          writer = csv.writer(csvfile)\n",
        "          writer.writerow([\"Server_Path\", \"Pred\", \"Confidence\"])\n",
        "          writer.writerows(dats)\n",
        "\n",
        "      print(\" meta (path, pred, conf) saved with length:\", len(dats))\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "mQPdduOobT-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model\n",
        "\n",
        "usually always need GPU for large data\n",
        "iterate through each epoch (eg. send model.to(GPU)) and send data.to(GPU)\n",
        " - epoch is one full run through of all the data\n",
        " - number of batches depends on the batch size\n",
        "- apply model\n",
        "- caluclate loss\n",
        "- zero/clear previous gradient\n",
        "- backpropgate loss\n",
        "- optimizer step"
      ],
      "metadata": {
        "id": "klj-GP3kjCRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accumulate run time and check if time >= max runtime if so evaluate(score = 0) so weights save\n",
        "# train based on hyper-params from config file and evaluate each epoch\n",
        "def train_eval(model, train_loader, test_loader, eval_loader, trainforms, testforms, loss_func, optimizer, epochs):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"Device\", device)\n",
        "    score = 0.0\n",
        "    model.to(device)\n",
        "    score = evaluate(model, test_loader, eval_loader, testforms, score)\n",
        "    t0 = time.time()\n",
        "    max_time = 20\n",
        "    write_ims = False\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        print(\"Epoch\", epoch + 1)\n",
        "        for step, batch in enumerate(train_loader):\n",
        "            x = batch['pixel_values'].float()\n",
        "            y = batch['labels'].float()\n",
        "            p = batch['protocol'].float()\n",
        "            c = batch['count'].float()\n",
        "            # x = trainforms(x)\n",
        "            x, y, p, c = x.to(device), y.to(device), p.to(device), c.to(device)\n",
        "            x = trainforms(x)\n",
        "            #out = model(x)\n",
        "            out = model(x, p, c)\n",
        "\n",
        "            loss = loss_func(out, y.unsqueeze(1))\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            t1 = time.time()\n",
        "            hours = (t1 - t0) / 3600\n",
        "        if (hours >= max_time):\n",
        "            write_ims = True\n",
        "            epcohs_passed = epoch + 1\n",
        "            print(\"Hours passed:\", hours)\n",
        "            return model, epochs_passed\n",
        "\n",
        "        score = evaluate(model, test_loader, eval_loader, testforms, score)\n",
        "    print(\"Final score: \", score)\n",
        "    score = evaluate(model, test_loader, eval_loader, testforms, score, test=False)\n",
        "    return model, epochs"
      ],
      "metadata": {
        "id": "Hok3VtVIjBVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##main function to call functions above and setup\n",
        "- different optimizers and loss functions:\n",
        "\n",
        "Optimizers: used to tune the parameters of a neural network in order to minimize the **cost function**\n",
        "-\n",
        "- 2 kinds adaptive and gradient descent\n",
        "  - adaptive: dont require LR tuning\n",
        "    - eg. Adam ( best - adds to the advantages of Adadelta and RMSprop, the storing of an exponentially decaying average of past gradients similar to momentum.)\n",
        "  - gradient descent:\n",
        "    - batch (entire dataset), stochastic (1 sample), mini-batch (1 batch at a time)\n",
        "\n",
        "    theta = theta - lambda * grad J( theta)\n",
        "\n",
        "- best choice depends on the type of problem (eg. regression vs classification)\n",
        "\n",
        "Loss functions: computes the distance of a single prediction from its actual value,\n",
        "\n",
        "- hyperparaters:\n",
        " - number of epochs: 1 epoch is one entire traversal of data through the network (eg. all samples have been passed through, n iterations = number of samples / batch size)\n",
        "  - depends on batch size, data size; maybe guess a number that should be enough in the beginning and then check it converges\n",
        " - train/test/eval batch sizes: smaller batch sizes may take longer to train (may be hard to converge if too small because of fluctiations)\n",
        "\n",
        " - learning rate: how much to update each weight in prop to loss (eg. how quickly stepping toward inflection point)\n",
        "  - to high causes issues (misses local minima\n",
        "  - to low causes issues (doesnt converge)\n"
      ],
      "metadata": {
        "id": "BAkCQYs6j74E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    # new = \"states/\" + month + day + year + dtime\n",
        "\n",
        "    # os.mkdir(new)\n",
        "\n",
        "    configParser = ConfigParser()\n",
        "    configParser.read('drp2.txt')\n",
        "\n",
        "    get_data = configParser[\"DATA\"]\n",
        "    train_ims_path = get_data['train_ims_path']\n",
        "    test_ims_path = get_data['test_ims_path']\n",
        "    train_meta_path = get_data[\"train_meta_path\"]\n",
        "    test_meta_path = get_data['test_meta_path']\n",
        "    train_label_col = -2#get_data['train_label_col']\n",
        "    test_label_col = 0#get_data['test_label_col']\n",
        "    meta_col = -1#get_data['meta_col']\n",
        "    #test meta col\n",
        "\n",
        "    cols = [int(train_label_col), int(test_label_col), int(meta_col)]\n",
        "    split = float(get_data[\"split\"])\n",
        "    k = int(get_data[\"k_fold\"])\n",
        "\n",
        "\n",
        "    print(\"Train, Valid Images array: \", train_ims_path)\n",
        "    print(\"Train, Valid Labels file: \", train_meta_path)\n",
        "    print(\"cols [train_label_col, test_label_col, meta_col]: \", cols)\n",
        "    print(\"k_fold, split:\", k, split)\n",
        "\n",
        "    get_model = configParser[\"MODEL\"]\n",
        "    model = get_model[\"model\"]\n",
        "    states = get_model[\"states\"]\n",
        "    print(\"Model used: \", model, \", states: \", states)\n",
        "    # add in model configs\n",
        "\n",
        "    get_params = configParser[\"PARAMS\"]  # batch size, LR/schedule, optimizer, epochs, DA\n",
        "    batch_size = int(get_params[\"batch_size\"])\n",
        "    epochs = int(get_params[\"epochs\"])\n",
        "    learning_rate = float(get_params[\"learning_rate\"])\n",
        "    print(\"Hyperperameters (batch size, epochs, learning rate): \", batch_size, epochs, learning_rate)\n",
        "\n",
        "    model0 = TFModel(ConvNextForImageClassification.from_pretrained(\"states/weights/convnext/\", ignore_mismatched_sizes=True, num_labels=126))#= torchvision.models.resnet18()\n",
        "    #model0.fc = torch.nn.Linear(512, 1)\n",
        "    if model == \"res18\":\n",
        "        model1 = model0\n",
        "    if model == \"FMW\":\n",
        "        model1 = FinalModelWrapper(model0)\n",
        "    if model == \"res-convnext\":\n",
        "      model1 = ConvNextForImageClassification.from_pretrained(\"states/weights/convnext/\", ignore_mismatched_sizes=True, num_labels=1)\n",
        "      model1 = TwoModelWrapper(model1, model0)\n",
        "    if model == \"res18\":\n",
        "      model1 = model0\n",
        "    if model == \"FMW\":\n",
        "      model1 = FinalModelWrapper(model0)\n",
        "    if model == \"MultiInputSimpleV\":\n",
        "      #model0.fc = torch.nn.Linear(512, 63)\n",
        "      model1 = MultiInputSimpleV(model0)\n",
        "    if model == \"convnext\":\n",
        "      model1 = TFModel(ConvNextForImageClassification.from_pretrained(\"states/weights/convnext/\", ignore_mismatched_sizes=True, num_labels=126))\n",
        "    # input mc labels or data paths if specified\n",
        "    #train_loader, test_loader, eval_loader, imnorm = prep_data_load(batch_size, train_ims_path, train_meta_path, test_ims_path, test_meta_path, cols, split, k)\n",
        "    train_loader, test_loader, eval_loader, imnorm = prep_data_load(batch_size, ['data/new2.npy', 'data/1260160.npy', 'data/711444_715276_715324_716189.npy', 'data/extractedTest1260s.npy'], ['data/new2.csv', 'data/1260160.csv', 'data/711444_715276_715324_716189.csv', 'data/1260_meta.csv'] , test_ims_path, test_meta_path, cols, split, k)\n",
        "    #  transforms used in current AMH prod code so supposably helpful (but we should double check)\n",
        "    t0 = RandomApply([ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)), RandomAffine(45, scale=(0.8, 1.5)),\n",
        "                      RandomAffine(45, shear=20)], p=0.8)\n",
        "    # update transforms if specified in config\n",
        "    trainforms = nn.Sequential(\n",
        "        imnorm,\n",
        "        # RandomCrop(480),\n",
        "        # t0\n",
        "    )\n",
        "    testforms = nn.Sequential(\n",
        "        imnorm,\n",
        "        # CenterCrop(480)\n",
        "    )\n",
        "\n",
        "    print(\"Transforms used: \", trainforms)\n",
        "\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "    optimizer = SGD(model1.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "    # scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    #ckpt = torch.load(states)\n",
        "    #model1.load_state_dict(ckpt['model_state_dict'])\n",
        "\n",
        "    #optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
        "\n",
        "    #epochs0 = epochs + ckpt['epochs_passed']\n",
        "    #print(\"Overall total epochs that should be trained after this: \", epochs0)\n",
        "\n",
        "    # scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "    print(\"Optimizer used: \", optimizer)\n",
        "\n",
        "    # update loss function if mc input\n",
        "    # loss_func = nn.CrossEntropyLoss()\n",
        "    loss_func = nn.BCEWithLogitsLoss()\n",
        "    '''\n",
        "    w_name = new + month + day + \"epoch\" + str(ckpt['epochs_passed']) + \"-first.pt\"\n",
        "    torch.save({'model_state_dict': model1.state_dict(),\n",
        "      'epochs_passed': ckpt['epochs_passed'],\n",
        "      'optimizer_state_dict': optimizer.state_dict()}, w_name)\n",
        "    print(\"First model saved to\", w_name)\n",
        "    '''\n",
        "    model, epochs_passed = train_eval(model1, train_loader, test_loader, eval_loader, trainforms, testforms, loss_func,\n",
        "                                      optimizer, epochs)\n",
        "    #epochs_passed += ckpt['epochs_passed']\n",
        "    '''\n",
        "    w_name = new + \"epoch_\" + str(epochs_passed) + \"-last.pt\"\n",
        "    torch.save({'model_state_dict': model.state_dict(),\n",
        "      'epochs_passed': epochs_passed,\n",
        "      'optimizer_state_dict': optimizer.state_dict()}, w_name)\n",
        "    print(\"Last model saved to\", w_name)\n",
        "    '''\n"
      ],
      "metadata": {
        "id": "RGj2py-Fj_qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e)"
      ],
      "metadata": {
        "id": "lyYGW5WDcc8F"
      }
    }
  ]
}